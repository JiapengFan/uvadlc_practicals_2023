============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius+and+Lisa#SoftwarepolicySnelliusandLisa-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
/var/spool/slurm/slurmd/job4534449/slurm_script: line 30: path_models: command not found
/var/spool/slurm/slurmd/job4534449/slurm_script: line 31: path_fixed: command not found
/var/spool/slurm/slurmd/job4534449/slurm_script: line 32: path_padding: command not found
/var/spool/slurm/slurmd/job4534449/slurm_script: line 33: path_deep: command not found
usage: Visual Prompting for CLIP [-h] [--print_freq PRINT_FREQ]
                                 [--save_freq SAVE_FREQ]
                                 [--batch_size BATCH_SIZE]
                                 [--num_workers NUM_WORKERS] [--epochs EPOCHS]
                                 [--square_size SQUARE_SIZE] [--optim OPTIM]
                                 [--learning_rate LEARNING_RATE]
                                 [--weight_decay WEIGHT_DECAY]
                                 [--warmup WARMUP] [--momentum MOMENTUM]
                                 [--patience PATIENCE] [--model MODEL]
                                 [--arch ARCH]
                                 [--prompt_type {visual_prompt,deep_prompt}]
                                 [--prompt_num PROMPT_NUM]
                                 [--injection_layer INJECTION_LAYER]
                                 [--method {padding,random_patch,fixed_patch}]
                                 [--prompt_size PROMPT_SIZE]
                                 [--text_prompt_template TEXT_PROMPT_TEMPLATE]
                                 [--root ROOT] [--dataset DATASET]
                                 [--image_size IMAGE_SIZE] [--test_noise]
                                 [--visualize_prompt] [--seed SEED]
                                 [--model_dir MODEL_DIR]
                                 [--image_dir IMAGE_DIR] [--filename FILENAME]
                                 [--trial TRIAL] [--resume RESUME]
                                 [--evaluate] [--gpu GPU] [--use_wandb]
Visual Prompting for CLIP: error: argument --method: invalid choice: 'fixed' (choose from 'padding', 'random_patch', 'fixed_patch')
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', prompt_type='visual_prompt', prompt_num=4, injection_layer=0, method='padding', prompt_size=0, text_prompt_template='This is a photo of a {}', root='/scratch-local/scur1301', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_0_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_0_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
=> no checkpoint found at '/model_best.pth.tar'
Turning off gradients in both the image and the text encoder
Parameters to be updated:
("Parameters to be updated: {'prompt_learner.pad_right', "
 "'prompt_learner.pad_down', 'prompt_learner.pad_up', "
 "'prompt_learner.pad_left'}")
Number of prompt parameters:  0
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  0%|          | 0/79 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part2/robustness.py", line 159, in <module>
    main()
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part2/robustness.py", line 153, in main
    learn.evaluate("test")
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/learner.py", line 290, in evaluate
    for i, (images, target) in enumerate(tqdm(loader)):
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/tqdm/std.py", line 1182, in __iter__
    for obj in iterable:
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 142, in <listcomp>
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 150, in collate
    raise TypeError(default_collate_err_msg_format.format(elem_type))
TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>

Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', prompt_type='deep_prompt', prompt_num=4, injection_layer=0, method='padding', prompt_size=0, text_prompt_template='This is a photo of a {}', root='/scratch-local/scur1301', dataset='cifar10', image_size=224, test_noise=True, visualize_prompt=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='padding_0_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume='/model_best.pth.tar', evaluate=True, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/padding_0_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
=> no checkpoint found at '/model_best.pth.tar'
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'deep_prompt'}"
Number of prompt parameters:  3072
Model evaluation w/ random noise
  0%|          | 0/79 [00:00<?, ?it/s]  0%|          | 0/79 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part2/robustness.py", line 159, in <module>
    main()
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part2/robustness.py", line 153, in main
    learn.evaluate("test")
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/learner.py", line 290, in evaluate
    for i, (images, target) in enumerate(tqdm(loader)):
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/tqdm/std.py", line 1182, in __iter__
    for obj in iterable:
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 142, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 142, in <listcomp>
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 150, in collate
    raise TypeError(default_collate_err_msg_format.format(elem_type))
TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>


JOB STATISTICS
==============
Job ID: 4534449
Cluster: snellius
User/Group: scur1301/scur1301
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:12:00 core-walltime
Job Wall-clock time: 00:00:40
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
