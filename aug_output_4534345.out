============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius+and+Lisa#SoftwarepolicySnelliusandLisa-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Executing with HORIZONTAL_FLIP augmentation...
/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Starting training.
Epoch: 1, Training accuracy: 0.42, Training loss: 2.6103, Validation accuracy: 0.54, Validation loss: 1.8391
Epoch: 2, Training accuracy: 0.56, Training loss: 1.7138, Validation accuracy: 0.57, Validation loss: 1.6019
Epoch: 3, Training accuracy: 0.59, Training loss: 1.5380, Validation accuracy: 0.58, Validation loss: 1.5220
Epoch: 4, Training accuracy: 0.6, Training loss: 1.4552, Validation accuracy: 0.59, Validation loss: 1.4856
Epoch: 5, Training accuracy: 0.62, Training loss: 1.3965, Validation accuracy: 0.59, Validation loss: 1.4857
Epoch: 6, Training accuracy: 0.63, Training loss: 1.3534, Validation accuracy: 0.59, Validation loss: 1.4658
Epoch: 7, Training accuracy: 0.63, Training loss: 1.3241, Validation accuracy: 0.59, Validation loss: 1.4617
Epoch: 8, Training accuracy: 0.64, Training loss: 1.3015, Validation accuracy: 0.59, Validation loss: 1.4527
Epoch: 9, Training accuracy: 0.64, Training loss: 1.2832, Validation accuracy: 0.59, Validation loss: 1.4486
Epoch: 10, Training accuracy: 0.65, Training loss: 1.2621, Validation accuracy: 0.59, Validation loss: 1.4470
Epoch: 11, Training accuracy: 0.65, Training loss: 1.2492, Validation accuracy: 0.6, Validation loss: 1.4335
Epoch: 12, Training accuracy: 0.65, Training loss: 1.2411, Validation accuracy: 0.6, Validation loss: 1.4353
Epoch: 13, Training accuracy: 0.66, Training loss: 1.2287, Validation accuracy: 0.6, Validation loss: 1.4439
Epoch: 14, Training accuracy: 0.66, Training loss: 1.2143, Validation accuracy: 0.59, Validation loss: 1.4498
Epoch: 15, Training accuracy: 0.66, Training loss: 1.2062, Validation accuracy: 0.6, Validation loss: 1.4255
Epoch: 16, Training accuracy: 0.66, Training loss: 1.1937, Validation accuracy: 0.59, Validation loss: 1.4345
Epoch: 17, Training accuracy: 0.66, Training loss: 1.1860, Validation accuracy: 0.6, Validation loss: 1.4368
Epoch: 18, Training accuracy: 0.67, Training loss: 1.1800, Validation accuracy: 0.6, Validation loss: 1.4388
Epoch: 19, Training accuracy: 0.67, Training loss: 1.1676, Validation accuracy: 0.6, Validation loss: 1.4504
Epoch: 20, Training accuracy: 0.67, Training loss: 1.1647, Validation accuracy: 0.6, Validation loss: 1.4300
Epoch: 21, Training accuracy: 0.67, Training loss: 1.1559, Validation accuracy: 0.59, Validation loss: 1.4563
Epoch: 22, Training accuracy: 0.67, Training loss: 1.1538, Validation accuracy: 0.59, Validation loss: 1.4642
Epoch: 23, Training accuracy: 0.67, Training loss: 1.1449, Validation accuracy: 0.59, Validation loss: 1.4574
Epoch: 24, Training accuracy: 0.67, Training loss: 1.1402, Validation accuracy: 0.59, Validation loss: 1.4542
Epoch: 25, Training accuracy: 0.68, Training loss: 1.1420, Validation accuracy: 0.6, Validation loss: 1.4533
Epoch: 26, Training accuracy: 0.68, Training loss: 1.1321, Validation accuracy: 0.59, Validation loss: 1.4642
Epoch: 27, Training accuracy: 0.68, Training loss: 1.1276, Validation accuracy: 0.59, Validation loss: 1.4458
Epoch: 28, Training accuracy: 0.68, Training loss: 1.1273, Validation accuracy: 0.6, Validation loss: 1.4652
Epoch: 29, Training accuracy: 0.68, Training loss: 1.1154, Validation accuracy: 0.59, Validation loss: 1.4738
Epoch: 30, Training accuracy: 0.68, Training loss: 1.1155, Validation accuracy: 0.6, Validation loss: 1.4563
Training finished.
Loading the best performing model on the validation data at Epoch 14 with validation accuracy 0.5962.
The test accuracy of the best performing model is 0.5952.
Executing with VERTICAL_FLIP augmentation...
/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Starting training.
Epoch: 1, Training accuracy: 0.35, Training loss: 2.8766, Validation accuracy: 0.5, Validation loss: 1.9989
Epoch: 2, Training accuracy: 0.48, Training loss: 2.0436, Validation accuracy: 0.53, Validation loss: 1.7443
Epoch: 3, Training accuracy: 0.51, Training loss: 1.8728, Validation accuracy: 0.55, Validation loss: 1.6732
Epoch: 4, Training accuracy: 0.52, Training loss: 1.7885, Validation accuracy: 0.55, Validation loss: 1.6247
Epoch: 5, Training accuracy: 0.53, Training loss: 1.7346, Validation accuracy: 0.56, Validation loss: 1.6101
Epoch: 6, Training accuracy: 0.54, Training loss: 1.6946, Validation accuracy: 0.56, Validation loss: 1.5968
Epoch: 7, Training accuracy: 0.55, Training loss: 1.6612, Validation accuracy: 0.56, Validation loss: 1.6012
Epoch: 8, Training accuracy: 0.55, Training loss: 1.6389, Validation accuracy: 0.57, Validation loss: 1.5890
Epoch: 9, Training accuracy: 0.56, Training loss: 1.6183, Validation accuracy: 0.57, Validation loss: 1.5745
Epoch: 10, Training accuracy: 0.56, Training loss: 1.6022, Validation accuracy: 0.57, Validation loss: 1.5804
Epoch: 11, Training accuracy: 0.57, Training loss: 1.5889, Validation accuracy: 0.57, Validation loss: 1.5715
Epoch: 12, Training accuracy: 0.56, Training loss: 1.5886, Validation accuracy: 0.57, Validation loss: 1.5732
Epoch: 13, Training accuracy: 0.57, Training loss: 1.5679, Validation accuracy: 0.56, Validation loss: 1.5881
Epoch: 14, Training accuracy: 0.57, Training loss: 1.5595, Validation accuracy: 0.56, Validation loss: 1.5883
Epoch: 15, Training accuracy: 0.58, Training loss: 1.5405, Validation accuracy: 0.57, Validation loss: 1.5703
Epoch: 16, Training accuracy: 0.58, Training loss: 1.5382, Validation accuracy: 0.57, Validation loss: 1.5632
Epoch: 17, Training accuracy: 0.58, Training loss: 1.5346, Validation accuracy: 0.57, Validation loss: 1.5636
Epoch: 18, Training accuracy: 0.58, Training loss: 1.5173, Validation accuracy: 0.56, Validation loss: 1.5708
Epoch: 19, Training accuracy: 0.58, Training loss: 1.5175, Validation accuracy: 0.57, Validation loss: 1.5812
Epoch: 20, Training accuracy: 0.58, Training loss: 1.5133, Validation accuracy: 0.57, Validation loss: 1.5630
Epoch: 21, Training accuracy: 0.59, Training loss: 1.4986, Validation accuracy: 0.57, Validation loss: 1.5917
Epoch: 22, Training accuracy: 0.59, Training loss: 1.5011, Validation accuracy: 0.56, Validation loss: 1.5901
Epoch: 23, Training accuracy: 0.59, Training loss: 1.4895, Validation accuracy: 0.56, Validation loss: 1.5931
Epoch: 24, Training accuracy: 0.59, Training loss: 1.4849, Validation accuracy: 0.57, Validation loss: 1.5784
Epoch: 25, Training accuracy: 0.59, Training loss: 1.4870, Validation accuracy: 0.57, Validation loss: 1.5687
Epoch: 26, Training accuracy: 0.59, Training loss: 1.4805, Validation accuracy: 0.56, Validation loss: 1.5936
Epoch: 27, Training accuracy: 0.59, Training loss: 1.4839, Validation accuracy: 0.57, Validation loss: 1.5781
Epoch: 28, Training accuracy: 0.59, Training loss: 1.4741, Validation accuracy: 0.57, Validation loss: 1.5964
Epoch: 29, Training accuracy: 0.59, Training loss: 1.4668, Validation accuracy: 0.56, Validation loss: 1.5968
Epoch: 30, Training accuracy: 0.59, Training loss: 1.4645, Validation accuracy: 0.56, Validation loss: 1.5873
Training finished.
Loading the best performing model on the validation data at Epoch 24 with validation accuracy 0.5648.
The test accuracy of the best performing model is 0.5575.
Executing with ROTATION augmentation...
Files already downloaded and verified
Traceback (most recent call last):
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part1/train.py", line 311, in <module>
    main(**kwargs)
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part1/train.py", line 273, in main
    model = train_model(model, lr, batch_size, epochs, data_dir, model_name, device, augmentation_name)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part1/train.py", line 128, in train_model
    cifar10_train, cifar_val = get_train_validation_set(data_dir, augmentation_name=augmentation_name)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part1/cifar100_utils.py", line 118, in get_train_validation_set
    add_augmentation(augmentation_name, train_transform)
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part1/cifar100_utils.py", line 83, in add_augmentation
    new_aug = transforms.RandomRotation()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: RandomRotation.__init__() missing 1 required positional argument: 'degrees'
Executing with TEST_NOISE augmentation...
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Starting training.
Traceback (most recent call last):
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part1/train.py", line 311, in <module>
    main(**kwargs)
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part1/train.py", line 273, in main
    model = train_model(model, lr, batch_size, epochs, data_dir, model_name, device, augmentation_name)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/uvadlc_practicals_2023/assignment2/part1/train.py", line 155, in train_model
    for i, (imgs, labels) in enumerate(cifar10_dataloader['train']):
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 674, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 49, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataset.py", line 364, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/utils/data/dataset.py", line 364, in <listcomp>
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torchvision/datasets/cifar.py", line 118, in __getitem__
    img = self.transform(img)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part1/cifar100_utils.py", line 50, in __call__
    noise = torch.sqrt(self.std)*normal_noise + self.mean
            ^^^^^^^^^^^^^^^^^^^^
TypeError: sqrt(): argument 'input' (position 1) must be Tensor, not float

JOB STATISTICS
==============
Job ID: 4534345
Cluster: snellius
User/Group: scur1301/scur1301
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 16:53:06 core-walltime
Job Wall-clock time: 00:56:17
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
