============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius+and+Lisa#SoftwarepolicySnelliusandLisa-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Running experiment on cifar10 with fixed_patch and prompt size 1
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=16, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', prompt_type='visual_prompt', prompt_num=4, injection_layer=0, method='fixed_patch', prompt_size=1, text_prompt_template='This is a photo of a {}', visualize_prompt=False, root='/scratch-local/scur1301', dataset='cifar10', image_size=224, test_noise=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume=None, evaluate=False, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /scratch-local/scur1301/cifar-10-python.tar.gz
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 65536/170498071 [00:00<07:16, 390593.05it/s]  0%|          | 229376/170498071 [00:00<03:55, 724263.78it/s]  1%|          | 917504/170498071 [00:00<01:16, 2227453.18it/s]  2%|▏         | 3309568/170498071 [00:00<00:20, 8208958.01it/s]  4%|▎         | 6389760/170498071 [00:00<00:11, 13869330.56it/s]  6%|▋         | 10682368/170498071 [00:00<00:07, 21911884.41it/s]  8%|▊         | 14221312/170498071 [00:00<00:06, 23467363.42it/s] 11%|█         | 18579456/170498071 [00:01<00:05, 28871339.96it/s] 13%|█▎        | 22249472/170498071 [00:01<00:04, 29712728.41it/s] 16%|█▌        | 26607616/170498071 [00:01<00:04, 33532433.17it/s] 18%|█▊        | 30212096/170498071 [00:01<00:04, 31153925.18it/s] 20%|██        | 34570240/170498071 [00:01<00:03, 34472882.17it/s] 23%|██▎       | 38404096/170498071 [00:01<00:03, 33887494.62it/s] 25%|██▌       | 42762240/170498071 [00:01<00:03, 36542947.69it/s] 27%|██▋       | 46530560/170498071 [00:01<00:03, 33325824.20it/s] 30%|██▉       | 50888704/170498071 [00:01<00:03, 36037692.12it/s] 32%|███▏      | 54624256/170498071 [00:02<00:03, 34918592.83it/s] 35%|███▍      | 59015168/170498071 [00:02<00:02, 37364272.93it/s] 37%|███▋      | 62849024/170498071 [00:02<00:03, 33996847.04it/s] 39%|███▉      | 67141632/170498071 [00:02<00:02, 36126686.10it/s] 42%|████▏     | 70877184/170498071 [00:02<00:02, 35241184.07it/s] 44%|████▍     | 75169792/170498071 [00:02<00:02, 33495763.11it/s] 47%|████▋     | 79527936/170498071 [00:02<00:02, 36094164.90it/s] 49%|████▉     | 83230720/170498071 [00:02<00:02, 34926050.23it/s] 51%|█████▏    | 87588864/170498071 [00:02<00:02, 37247982.25it/s] 54%|█████▎    | 91389952/170498071 [00:03<00:02, 33899573.59it/s] 56%|█████▌    | 95191040/170498071 [00:03<00:02, 34979264.08it/s] 58%|█████▊    | 99090432/170498071 [00:03<00:02, 34751747.36it/s] 60%|██████    | 102957056/170498071 [00:03<00:01, 35803572.17it/s] 63%|██████▎   | 106594304/170498071 [00:03<00:01, 35343702.99it/s] 65%|██████▍   | 110166016/170498071 [00:03<00:01, 32694114.41it/s] 67%|██████▋   | 114524160/170498071 [00:03<00:01, 33307716.98it/s] 70%|██████▉   | 118587392/170498071 [00:03<00:01, 35256601.21it/s] 72%|███████▏  | 122191872/170498071 [00:04<00:01, 35207152.78it/s] 74%|███████▍  | 125763584/170498071 [00:04<00:01, 32581137.88it/s] 76%|███████▌  | 129957888/170498071 [00:04<00:01, 35078025.27it/s] 78%|███████▊  | 133529600/170498071 [00:04<00:01, 33492835.01it/s] 80%|████████  | 137134080/170498071 [00:04<00:00, 34178942.67it/s] 82%|████████▏ | 140607488/170498071 [00:04<00:00, 34318983.15it/s] 85%|████████▍ | 144113664/170498071 [00:04<00:00, 32037227.64it/s] 87%|████████▋ | 147816448/170498071 [00:04<00:00, 33397341.32it/s] 89%|████████▉ | 151322624/170498071 [00:04<00:00, 33827345.10it/s] 91%|█████████ | 155058176/170498071 [00:05<00:00, 33567098.54it/s] 93%|█████████▎| 159055872/170498071 [00:05<00:00, 35356798.62it/s] 95%|█████████▌| 162791424/170498071 [00:05<00:00, 35915445.67it/s] 98%|█████████▊| 166428672/170498071 [00:05<00:00, 32116436.74it/s]100%|█████████▉| 170393600/170498071 [00:05<00:00, 34115026.82it/s]100%|██████████| 170498071/170498071 [00:05<00:00, 31275881.23it/s]
Extracting /scratch-local/scur1301/cifar-10-python.tar.gz to /scratch-local/scur1301
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
  0%|                                               | 0.00/338M [00:00<?, ?iB/s]  1%|▎                                     | 2.64M/338M [00:00<00:12, 27.7MiB/s]  3%|▉                                     | 8.72M/338M [00:00<00:07, 47.2MiB/s]  4%|█▋                                    | 14.8M/338M [00:00<00:06, 54.7MiB/s]  6%|██▎                                   | 20.3M/338M [00:00<00:05, 55.6MiB/s]  8%|██▉                                   | 25.6M/338M [00:00<00:06, 51.2MiB/s]  9%|███▌                                  | 31.2M/338M [00:00<00:06, 53.5MiB/s] 11%|████▏                                 | 37.2M/338M [00:00<00:05, 56.3MiB/s] 13%|████▊                                 | 42.9M/338M [00:00<00:05, 57.1MiB/s] 15%|█████▊                                | 51.5M/338M [00:00<00:04, 67.3MiB/s] 18%|██████▊                               | 60.5M/338M [00:01<00:03, 75.5MiB/s] 22%|████████▏                             | 72.6M/338M [00:01<00:03, 90.9MiB/s] 24%|█████████▏                            | 81.3M/338M [00:01<00:03, 78.8MiB/s] 26%|██████████                            | 89.1M/338M [00:01<00:03, 76.2MiB/s] 29%|██████████▊                           | 96.6M/338M [00:01<00:03, 72.9MiB/s] 31%|████████████▏                          | 106M/338M [00:01<00:03, 78.4MiB/s] 34%|█████████████                          | 113M/338M [00:01<00:03, 78.4MiB/s] 36%|██████████████                         | 122M/338M [00:01<00:02, 82.9MiB/s] 39%|███████████████▏                       | 131M/338M [00:01<00:02, 86.2MiB/s] 42%|████████████████▍                      | 142M/338M [00:02<00:02, 93.5MiB/s] 45%|█████████████████▍                     | 151M/338M [00:02<00:02, 92.7MiB/s] 47%|██████████████████▌                    | 160M/338M [00:02<00:01, 94.6MiB/s] 50%|███████████████████▌                   | 170M/338M [00:02<00:01, 95.1MiB/s] 53%|████████████████████▋                  | 179M/338M [00:02<00:01, 92.7MiB/s] 56%|█████████████████████▋                 | 188M/338M [00:02<00:02, 77.4MiB/s] 58%|██████████████████████▌                | 195M/338M [00:02<00:02, 74.0MiB/s] 60%|███████████████████████▌               | 204M/338M [00:02<00:01, 77.4MiB/s] 63%|████████████████████████▋              | 214M/338M [00:02<00:01, 85.0MiB/s] 66%|█████████████████████████▉             | 224M/338M [00:03<00:01, 90.8MiB/s] 69%|██████████████████████████▉            | 233M/338M [00:03<00:01, 89.5MiB/s] 72%|███████████████████████████▉           | 242M/338M [00:03<00:01, 84.3MiB/s] 74%|████████████████████████████▉          | 250M/338M [00:03<00:01, 85.9MiB/s] 77%|█████████████████████████████▊         | 259M/338M [00:03<00:01, 80.1MiB/s] 79%|██████████████████████████████▊        | 266M/338M [00:03<00:00, 78.6MiB/s] 81%|███████████████████████████████▋       | 274M/338M [00:03<00:00, 77.1MiB/s] 83%|████████████████████████████████▌      | 281M/338M [00:03<00:00, 74.6MiB/s] 86%|█████████████████████████████████▍     | 289M/338M [00:03<00:00, 75.9MiB/s] 88%|██████████████████████████████████▏    | 296M/338M [00:04<00:00, 73.4MiB/s] 91%|███████████████████████████████████▍   | 307M/338M [00:04<00:00, 83.4MiB/s] 94%|████████████████████████████████████▋  | 317M/338M [00:04<00:00, 92.0MiB/s] 97%|█████████████████████████████████████▋ | 326M/338M [00:04<00:00, 92.0MiB/s]100%|██████████████████████████████████████▊| 336M/338M [00:04<00:00, 94.5MiB/s]100%|███████████████████████████████████████| 338M/338M [00:04<00:00, 79.2MiB/s]
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
Turning off gradients in both the image and the text encoder
Parameters to be updated:
Parameters to be updated: {'prompt_learner.patch'}
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
  0%|          | 0/313 [00:00<?, ?it/s]/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/autograd/__init__.py:251: UserWarning: Error detected in LinalgVectorNormBackward0. Traceback of forward call that caused the error:
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/.//main.py", line 153, in <module>
    main()
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/.//main.py", line 147, in main
    learn.run()
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/learner.py", line 162, in run
    self.train_one_epoch(epoch)
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/learner.py", line 244, in train_one_epoch
    output = self.clip(images)
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/vpt_model.py", line 123, in forward
    image_features /= image_features.norm(dim=-1, keepdim=True)
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/_tensor.py", line 708, in norm
    return torch.norm(self, p, dim, keepdim, dtype=dtype)
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/functional.py", line 1595, in norm
    return torch.linalg.vector_norm(input, 2, _dim, keepdim, dtype=dtype)
 (Triggered internally at /opt/conda/conda-bld/pytorch_1695392026823/work/torch/csrc/autograd/python_anomaly_mode.cpp:114.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  0%|          | 0/313 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/.//main.py", line 153, in <module>
    main()
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/.//main.py", line 147, in main
    learn.run()
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/learner.py", line 162, in run
    self.train_one_epoch(epoch)
  File "/gpfs/home6/scur1301/uvadlc_practicals_2023/assignment2/part2/learner.py", line 246, in train_one_epoch
    loss.backward()
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/home/scur1301/.conda/envs/dl2023/lib/python3.11/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.HalfTensor [128, 512]], which is output 0 of DivBackward0, is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!

JOB STATISTICS
==============
Job ID: 4526325
Cluster: snellius
User/Group: scur1301/scur1301
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:11:06 core-walltime
Job Wall-clock time: 00:00:37
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 31.25 GB (31.25 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
